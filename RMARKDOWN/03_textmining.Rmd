---
output: html_document
editor_options: 
  chunk_output_type: console
---
<!--      
Essa Rotina é destinada a importação de dados do projeto de mineração de texto em pedidos via Sistema Eletrônico de Serviço de Informação ao Cidadão (e-SIC)
-->
### Palavras por pedido 
> Análise2: distribuição de frequência de palavras por diretoria e algumas estatísticas descritivas

#### Ferramentas
Iniciamos as manipulações utilizando recursos da função `unnest_tokens( )` do pacote `library(tidytext)` que nos permite trabalhar com textos em um formato `tidy`, ou seja que coloca uma palavra por linha em uma única coluna, formando, assim, _termos/palavras_ por linha. Utilizamos, também, ainda os recursos do pacote `library(diplyr)` para, posteriormente, agrupar esses termos por diretoria e calcular a frequência dos _termos_.

Verificamos que as 10 palavras mais frequentes em todos os pedidos realizados são palavras sem acréscimo contextual, pois essas não acrescentam nenhum sentido semântico como, por exemplo: preposições (de, da, do, para, em, no), conjunção (e) e artigos(o,a). 

Citar o que é preoposição.

#### Tabela3: Palavras mais frequentes
- Tabela 03 Palavras mais frequentes no conjunto de solicitações por diretoria
```{r}
library(tidytext)
palavras <- DB %>%
  unnest_tokens(palavra, DESCRI_PEDIDO) %>%
  count(palavra, sort = TRUE) %>%
  ungroup()

palavras[0:10,] %>%
  kable("latex", caption = "Principais palavras com stopwords", 
        booktabs = T, format.args = list(decimal.mark = ',', big.mark = ".")) %>%
  kable_styling(latex_options = c("striped", "hold_position"))
```

#### Tabelas4,5,6: Palavras mais frequentes por diretoria

##### Tabelas4: Palavras mais frequentes DEA
- Tabela 04 Palavras mais frequentes no conjunto de solicitações por diretoria
```{r}
palavras_diretoria <- DB %>%
  unnest_tokens(palavra, DESCRI_PEDIDO) %>%
  count(DIRETORIA,palavra, sort = TRUE) %>%
  ungroup() %>%  droplevels() %>% drop_na()


palavras_diretoria %>%
  filter(DIRETORIA == "DEA") %>%
    top_n(n = 10) %>%
  kable("latex", caption = "Principais palavras com stopwords (DEA)", 
        booktabs = T, format.args = list(decimal.mark = ',', big.mark = ".")) %>%
  kable_styling(latex_options = c("striped", "hold_position"))
```

##### Tabelas5: Palavras mais frequentes DEE
- Tabela 05 Palavras mais frequentes no conjunto de solicitações por diretoria
```{r}
palavras_diretoria %>%
  filter(DIRETORIA == "DEE") %>%
    top_n(n = 10) %>%
  kable("latex", caption = "Principais palavras com stopwords (DEA)", 
        booktabs = T, format.args = list(decimal.mark = ',', big.mark = ".")) %>%
  kable_styling(latex_options = c("striped", "hold_position"))
```

##### Tabelas6: Palavras mais frequentes DEA
- Tabela 06 Palavras mais frequentes no conjunto de solicitações por diretoria
```{r}
palavras_diretoria %>%
  filter(DIRETORIA == "OUTROS") %>%
    top_n(n = 10) %>%
  kable("latex", caption = "Principais palavras com stopwords (OUTROS)", 
        booktabs = T, format.args = list(decimal.mark = ',', big.mark = ".")) %>%
  kable_styling(latex_options = c("striped", "hold_position"))
```

Mesmo assim, abrindo para cada uma das 3 possíveis cateogorias da variável **Diretoria** temos que as principais palavras não agregam nenhum valor semântico, exceto pela palavra energia que apareceu na oitava e nona colocação de maior frequência dos documentos de pedidos enviados à _DEA_ e _DEE_, respectivamente. Isso devido ao excesso de uso de **stop words** em textos humanos.

Nos passos seguintes iremos remover essas palavras, **stop words**, e trabalhar apenas com palavras de sentido semântico relevante aos subjetivos solicitados às diretorias, acrescentando assim maior assertividade na classificação do nosso modelo, objetivo principal desse estudo.

Verificamos, antes disso, o total, freq. e média de palavras por diretoria, bem como comparações 2 a 2 para cada uma das categorias.

### Análise2: Comparação de freq. de palavras por diretoria

- Total de palavras por diretoria, total de pedidos por diretoria e número médio de palavras por pedido e diretoria
```{r}
total_palavras = palavras_diretoria %>%
  group_by(DIRETORIA) %>%
  summarize(total_palavras = sum(n))

total_palavras = left_join(x = total_palavras, y = pedidos_diretoria1, 
                           by = "DIRETORIA") %>%
mutate(media_palavras_porpedidoEdiretoria = total_palavras/total_pedidos)
```

#### Tabelas7: Total de palavras por diretoria, total de pedidos por diretoria e número médio de palavras por pedido e diretoria
- Total de palavras por diretoria, total de pedidos por diretoria e número médio de palavras por pedido e diretoria
```{r}
total_palavras %>%
  kable("latex", caption = "Total de palavras, total de pedidos e número médio de palavras
        por pedido e diretoria", 
        booktabs = T, format.args = list(decimal.mark = ',', big.mark = ".")) %>%
  kable_styling(latex_options = c("striped", "hold_position"))
```

Temos que o número médio de palavras por pedido é parecido entre as diretorias. com médias de 55 palavras por pedido para DEE e 69,7 e 61,7, respectivamente para DEA e OUTROS.

#### Figura1: Distribuição de frequência de termos por diretoria
- Distribuição da freq. de palavras usadas em solicitações por diretoria (histograma)
```{r}
diretoria_palavras <- DB %>%
  unnest_tokens(palavra, DESCRI_PEDIDO) %>%
  count(DIRETORIA, palavra, sort = TRUE) %>%
  ungroup()

diretoria_palavras = left_join(diretoria_palavras, total_palavras, by = "DIRETORIA")

library(ggplot2)
gcomma <- function(x) format(x, big.mark = ".", decimal.mark = ",", scientific = FALSE)

ggplot(diretoria_palavras, aes(n/total_palavras, fill = DIRETORIA)) + 
  geom_histogram(show.legend = FALSE) + xlim(NA, 0.0021) +
facet_wrap(~DIRETORIA, ncol = 2, scales = "free_y") + 
  scale_y_continuous(labels=gcomma)  +
  scale_x_continuous(labels=gcomma, limits = c(NA, 0.0021))
```

Pelos histogramas fica claro que as distribuições da frequência de termos por diretoria possuem caudas mais alongadas à direita, isso sem contar algumas frequências que não foram evidenciadas nessas figuras por questões de escala, do contrário seria possível, apenas, ver a frequência das palavras mais recorrentes no texto que, como vimos até o momento, são as de menor relevância em contexto e semântica.

Sabemos, portanto, que queremos encontrar valor exatamente nas partes mais longas à direita das distribuições de frequência de termos, uma vez que ali se encontram as palavras de maior valor contextual. 

Logo, a seguir, usamos da definição da lei **Zipf** que afirma que a frequência que uma palavra (ou termo) aparece em um documento é inversamente proporcional ao seu ranque.

> lei de Zipf's

Citar, aqui, "There are very long tails to the right for these novels (those extremely common words!) that we have not shown in these plots. These plots exhibit similar distributions for all the novels, with many words that occur rarely and fewer words that occur frequently." pág. 31 (Silge, Robinson). Que averigua que documentos de texto tendem a ter distribuições de frequência de palavras similar, por conta das stopwords. 

Ainda de acordo com os autores, "Distributions like those shown in Figure 3-1 are typical in language. In fact, those types of long-tailed distributions are so common in any given corpus of natural lan‐ guage (like a book, or a lot of text from a website, or spoken words) that the relation‐ ship between the frequency that a word is used and its rank has been the subject of study." e por essa razão e a relação verificada por George Zipf da relação inversa entre freq. de palavra e ranque tiramos valor dos documentos partindo dessas premissas.

- Ranque de palavras pela pela lei de **Zipf**
```{r}
freq_by_rank <- diretoria_palavras %>%
group_by(DIRETORIA) %>%
mutate(ranque = row_number(),
`frequência de termos` = n/total_palavras)
```


#### Figura1: Lei de Zipf 
- Zipf's law
```{r}
#plot1
freq_by_rank %>%
ggplot(aes(ranque, `frequência de termos`, color = DIRETORIA)) +
  geom_line(size = 1.1, alpha = 0.8, show.legend = FALSE) + scale_x_log10() +
  scale_y_log10()
```

Vemos que exatamente nas extremidades do gráfico tem-se uma não sobreposição de frequências por diretoria. Detalhe que o gráfico, em questão, está na escala logarítmica no eixo x (ranque) e eixo y (freq. de termos). Plotando desta forma, a relação inversamente proporcional terá uma inclinação constante e negativa.

Tendo em vista, portanto, que o gráfico referido está em cordenadas log-log e dado a semelhança de todos os documentos de texto das diferentes diretorias, afirmamos que para todas as diretorias pela Lei de **Zipf** a relação entre ranque e freq. de termos assumirá, sempre, uma inclinação negativa, ou seja, 

<!--
$$
\begin{equation} \label{eq:zif}
frequência \propto \frac{1}{ranque}
\end{equation}
$$
--> 

Daí, aplicando a escala log-log temos que e podemos aplicar um ajuste a fim de encontrar um intercepto e coef. angular para traçar no gráfico anterior.

$$
frequência \propto \frac{1}{ranque} \implies log(frequência) \propto log\left(\frac{1}{ranque}\right)
$$

Reescrever e exlicar a seguimentação em 3 partes como uma "lei de potenciacao dividida em 3 partes" e então utilizar do seguimento do meio, onde as freq. de ternos sao mais semelhantes para diferentes ranques das diferentes diretorias. Fica claro pela eq. <!--$\ref{eq:zif}$-->

"Notice that Figure 3-2 is in log-log coordinates. We see that all six of Jane Austen’s novels are similar to each other, and that the relationship between rank and fre‐ quency does have negative slope. It is not quite constant, though; perhaps we could view this as a broken power law with, say, three sections. Let’s see what the exponent of the power law is for the middle section of the rank range."

```{r}
rank_subset <- freq_by_rank %>%
      filter(ranque < 500, ranque > 50)

(zipf_ajusteloglog <- lm(log10(`frequência de termos`) ~ log10(ranque), 
                         data = rank_subset))
```

Finalmente, traçando e sobrepondo o gráfico anterior com os valores de initercepto e coeficiente angular obtidos no ajuste do passo anterior temos a figura a seguir.

#### Figura1: Lei de Zipf + ajuste log-log
```{r}
freq_by_rank %>%
ggplot(aes(ranque, `frequência de termos`, color = DIRETORIA)) +
geom_abline(intercept = coefficients(zipf_ajusteloglog)[1], slope = coefficients(zipf_ajusteloglog)[2], color = "gray50", linetype = 2) +
geom_line(size = 1.1, alpha = 0.8, show.legend = TRUE) +
scale_x_log10(labels=gcomma) +
scale_y_log10(labels=gcomma)
```


#### The Bind **tf_idf**
Fundamentar o uso da estatística **tf_idf**, bem como descrever a definição. 

> The idea of tf-idf is to find the important words for the content of each document by decreasing the weight for commonly used words and increasing the weight for words that are not used very much in a collection or corpus of documents, in this case, the group of Jane Austen’s novels as a whole. Calculating tf-idf attempts to find the words that are important (i.e., common) in a text, but not too common. Let’s do that now.
The bind_tf_idf function in the tidytext package takes a tidy text dataset as input with one row per token (term), per document. One column (word here) contains the terms/tokens, one column contains the documents (book in this case), and the last necessary column contains the counts, or how many times each document contains each term (n in this example). We calculated a total for each book for our explora‐ tions in previous sections, but it is not necessary for the bind_tf_idf function; the table only needs to contain all the words in each document.

```{r}
round_df <- function(x, digits) {
    # round all numeric variables
    # x: data frame 
    # digits: number of digits to round
    numeric_columns <- sapply(x, mode) == 'numeric'
    x[numeric_columns] <-  round(x[numeric_columns], digits)
    x
}
```


- Palavras mais relevantes de acordo com a estatística **tf_idf**
```{r}
diretoria_palavras_tfidf <- diretoria_palavras %>%
  bind_tf_idf(palavra, DIRETORIA, n) %>%
  select(-total_palavras, -total_pedidos, -media_palavras_porpedidoEdiretoria) %>%
  arrange(desc(tf_idf))

#options(digits=4)
set.seed(7456)
amostra1 = sample(seq(1:dim(diretoria_palavras_tfidf)[1]), 10, replace = FALSE)
round_df(diretoria_palavras_tfidf[amostra1,],5) # %>%
  kable("latex", caption = "Total de palavras, total de pedidos e número médio de palavras 
        por pedido e diretoria", 
        booktabs = T, format.args = list(decimal.mark = ',', big.mark = ".")) %>%
  kable_styling(latex_options = c("striped", "hold_position"))
```

A estatística faz um trabalho brilhante ao ressaltar as palavras mais relevantes dentro de cada conjunto de documentos (diretorias). As tabelas a seguir mostram as 10 palavras mais relevantes de acordo com a estatística tf_idf por diretoria

##### Tabela8: top 12 termos ordenados pela estatística **tf_idf** (DEE)
```{r}
round_df(diretoria_palavras_tfidf,5) %>%
  filter(DIRETORIA == "DEE") %>%
  top_n(12,tf_idf) %>%
  kable("latex", caption = "Top 10 termos (DEE)", 
        booktabs = T, format.args = list(decimal.mark = ',', big.mark = ".")) %>%
  kable_styling(latex_options = c("striped", "hold_position"))
```

##### Tabela9: top 12 termos ordenados pela estatística **tf_idf** (DEA)
```{r}
round_df(diretoria_palavras_tfidf,5) %>%
  filter(DIRETORIA == "DEA") %>%
  top_n(12,tf_idf) %>%
  kable("latex", caption = "Top 10 termos (DEA)", 
        booktabs = T, format.args = list(decimal.mark = ',', big.mark = ".")) %>%
  kable_styling(latex_options = c("striped", "hold_position"))
```

##### Tabela10: top 10 termos ordenados pela estatística **tf_idf** (OUTROS)
```{r}
round_df(diretoria_palavras_tfidf,5) %>%
  filter(DIRETORIA == "OUTROS") %>%
  top_n(12,tf_idf) %>%
  kable("latex", caption = "Top 10 termos (DEA)", 
        booktabs = T, format.args = list(decimal.mark = ',', big.mark = ".")) %>%
  kable_styling(latex_options = c("striped", "hold_position"))
```

Ou simplesmente verificamos através de um gráfico

##### Figura2: Termos mais relevantes por diretoria pela estatística **tf_idf**
```{r}
diretoria_palavras <- DB %>%
  unnest_tokens(palavra, DESCRI_PEDIDO) %>%
  count(DIRETORIA, palavra, sort = TRUE) %>%
  ungroup()
diretoria_palavras = left_join(diretoria_palavras, total_palavras, by = "DIRETORIA")
```

##### Figura3: Top 10 termos por diretoria (ordenados pela estatística **tf_idf** e com **stop words** e sem **stemming**
```{r 02_freq_palavras_dir, fig.width=9, fig.height=7}
plot_diretoria_palavras <- diretoria_palavras %>%
  bind_tf_idf(palavra, DIRETORIA, n) %>%
  arrange(desc(tf_idf)) %>%
  mutate(palavra = factor(palavra, levels = rev(unique(palavra)))) %>%
  mutate(DIRETORIA = factor(DIRETORIA, levels = c("DEA","DEE","OUTROS")))
#View(head(plot_diretoria_palavras))
#jpeg("02_freq_palavras_dir.jpeg")
plot_diretoria_palavras %>%
  group_by(DIRETORIA) %>%
  top_n(10, tf_idf) %>%
  ungroup() %>%
  mutate(palavra = reorder(palavra, tf_idf)) %>%
  ggplot(aes(palavra, tf_idf, fill = DIRETORIA)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "tf-idf") +
  facet_wrap(~DIRETORIA, ncol = 2, scales = "free") +
  coord_flip() + 
  scale_y_continuous(labels=gcomma)
#dev.off()
```

#### Filtrando um pedaço de texto
```{r}
DB %>%
  filter(str_detect(DESCRI_PEDIDO, "r0")) %>%
  select(DESCRI_PEDIDO) %>%
  head()
```

Uma limpeza removendo palavras sem significado semântico (**stop words**) pode auxiliar o algoritmo a retornar palavras ainda mais acertivas, bem como o tratamento de **stemming**, abordados a seguir.


### Stemming

Podemos diminuir redundâncias por parte do algoritmo ensinando-o a compreender palavras que podem estar escritas de forma diferente mas que em significado semântico são semelhantes. Para isso, analisamos o radical de palavras com um mesmo prefixo mas com sufixos diferentes seja por quisistos como gênero ou plural.

Exemplos:
  
leilão $\propto$ leilões
estado $\propto$ estados
região $\propto$ regiões

Usando o pacote `ptstem`
```{r}
library(ptstem)
stemming1 = ptstem(DB$DESCRI_PEDIDO)
```
  
- Frequência de palavras por diretoria do stemming 1
```{r}
diretoria_palavras_stem1 <- DB %>%
  mutate(DESCRI_PEDIDO = stemming1) %>%
  unnest_tokens(palavra, DESCRI_PEDIDO) %>%
  count(palavra, sort = TRUE) %>%
  ungroup()
```

```{r}
cat(paste0("Utilizando o algoritmo de stemming do pacote 'ptstem' o número de palavras chaves sem stemming reduziu de ", dim(diretoria_palavras)[1], " para ", dim(diretoria_palavras_stem1)[1], ", após stemming. Uma redução de ",round(100-dim(diretoria_palavras_stem1)[1]*100/dim(diretoria_palavras)[1],0),"%."))
```

Usando o pacote `rslp`
```{r}
library(rslp)
stemming2 = rslp(DB$DESCRI_PEDIDO)
```

- Frequência de palavras por diretoria do stemming 2
```{r}
diretoria_palavras_stem2 <- DB %>%
  mutate(DESCRI_PEDIDO = stemming2) %>%
  unnest_tokens(palavra, DESCRI_PEDIDO) %>%
  count(palavra, sort = TRUE) %>%
  ungroup()
```

```{r}
cat(paste0("Utilizando o algoritmo de stemming do pacote 'rslp' o número de palavras chaves sem stemming reduziu de ", dim(diretoria_palavras)[1], " para ", dim(diretoria_palavras_stem2)[1], ", após stemming. Uma redução de ", round(100-dim(diretoria_palavras_stem2)[1]*100/dim(diretoria_palavras)[1],0),"%."))
```


Uma redução considerável no número de termos ocorreu ao usar o algoritmo `ptstem`, cerca de $33\%$ de redução de termos versus $7\%$ utilziando o algoritmo `rslp`, ou seja, o algoritmo ptstem foi mais eficiente na tarefa de agrupar os semelhantes (termos únicos).

Vale ressaltar, tabmbém, o tempo de processamento que ambos os algoritmos requerem.

```{r}
temp_stem1 = proc.time()
teste0 = ptstem(DB$DESCRI_PEDIDO)
tempo_stem1 = proc.time() - temp_stem1
remove(teste0)
```

```{r}
temp_stem2 = proc.time()
teste00 = rslp(DB$DESCRI_PEDIDO)
tempo_stem2 = proc.time() - temp_stem2
remove(teste00)
```

O tempo decorrido para processamento do algoritmo do `ptstem` foi de aproximadamente 12,5 segundos versus 0,9 segundo decorrido para o processamento do algoritmo do `rslp`. Logo, o `rslp` é quase 14 vezes mais eficiente em termos de tempo de processamento. Além disso, o `rslp` remove acentuações e caracteres como "ç". Isso irá nos ajudar mais a frente quando utilizarmos os principais termos como variáveis binárias e preditoras do modelo de classificação.

Entretanto, o algoritmo mais lento, `ptstem`, foi mais interessante em termos de redução do número de termos únicos, cerca de 26% menos termos únicos em relação ao outro algoritmo. Além disso, por se tratar de uma base de dados relativamente pequena, 625 pedidos, e pouco mais de 4 mil termos únicos em todo o conjunto de texto, além disso vamos utilizar de um alto poder de processamento da máquina no referido estudo. Optamos, portanto, por utilizar ambos algoritmos. Vamos, primeiro, aplicar o removedor de sufixos da lingua portuguesa `rslp` seguido do `ptstem`.

Cria, antes, uma variáveil DESCRI_PEDIDO1 que repete os passos feitos aos termos quanto ao stemming so que no texto fonte.
```{r}
### CARACTERES
DB$DESCRI_PEDIDO1 = DB$DESCRI_PEDIDO
DB$DESCRI_PEDIDO1 = gsub("-","",DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 = gsub("[:.:]","",DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 = gsub("[:,:]","",DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 = gsub("[:':]","",DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 = gsub("[:!:]","",DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 = gsub("[:?:]","",DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 = gsub("[:-:]","",DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 = gsub("[:__:]","",DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 = gsub("[:;:]","",DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 = gsub("[:/:]","",DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 = gsub("[:(:]","",DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 = gsub("[:):]","",DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 = gsub("[:%:]","",DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 = gsub("[:º:]","",DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 = gsub("[:°:]","",DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 = gsub("[:ª:]","",DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 = gsub("\\d+","",DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 = gsub("[0-9]","",DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 = gsub("[:\n\t:]"," ",DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 = gsub("[:\t:]","",DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 = gsub("[:\n:]","",DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 = gsub("\\s+"," ",DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 = gsub("\"","",DB$DESCRI_PEDIDO1)

### STEMMINGS
DB$DESCRI_PEDIDO1 = ptstem(rslp(DB$DESCRI_PEDIDO1), algorithm = "hunspell", 
                           complete = TRUE)
DB$DESCRI_PEDIDO1 = rslp(ptstem(DB$DESCRI_PEDIDO1))
DB$DESCRI_PEDIDO1 = gsub("\\s+"," ",DB$DESCRI_PEDIDO1)


### PALAVRAS
DB$DESCRI_PEDIDO1 =gsub("\\b(Leiloes)", "leilao", DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 =gsub("\\b(Leiloar)", "leilao", DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 =gsub("\\b(leiloes)", "leilao", DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 =gsub("\\b(leiloar)", "leilao", DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 =gsub("\\b(leiloes)", "leilao", DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 =gsub("\\b(Energetica)", "eletrica", DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 =gsub("\\b(energetica)", "eletrica", DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 =gsub("\\b(Eletricas)", "eletrica", DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 =gsub("\\b(eletricas)", "eletrica", DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 =gsub("\\b(Eletricos)", "eletrica", DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 =gsub("\\b(eletricos)", "eletrica", DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 =gsub("\\b(Eletrico)", "eletrica", DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 =gsub("\\b(eletrico)", "eletrica", DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 =gsub("\\b(Eletricidade)", "eletrica", DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 =gsub("\\b(eletricidade)", "eletrica", DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 =gsub("\\b(Termoeletricas)", "termoeletrica", DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 =gsub("\\b(termoeletricas)", "termoeletrica", DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 =gsub("\\b(Termeletrica)", "termoeletrica", DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 =gsub("\\b(termeletrica)", "termoeletrica", DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 =gsub("\\b(Termeletricas)", "termoeletrica", DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 =gsub("\\b(termeletricas)", "termoeletrica", DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 =gsub("\\b(Hidreletricas)", "hidreletrica", DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 =gsub("\\b(hidreletricas)", "hidreletrica", DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 =gsub("\\b(Hidroeletricas)", "hidreletrica", DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 =gsub("\\b(hidroeletricas)", "hidreletrica", DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 =gsub("\\b(Hidroeletricos)", "hidreletrica", DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 =gsub("\\b(hidroeletricos)", "hidreletrica", DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 =gsub("\\b(Hidroeletrica)", "hidreletrica", DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 =gsub("\\b(hidroeletrica)", "hidreletrica", DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 =gsub("\\b(Administracao)", "administracao", DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 =gsub("\\b(administracao)", "administracao", DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 =gsub("\\b(Administrativo)", "administracao", DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 =gsub("\\b(administrativo)", "administracao", DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 =gsub("\\b(Administrativos)", "administracao", DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 =gsub("\\b(administrativos)", "administracao", DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 =gsub("\\b(Administrativa)", "administracao", DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 =gsub("\\b(administrativa)", "administracao", DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 =gsub("\\b(Administrativas)", "administracao", DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 =gsub("\\b(administrativas)", "administracao", DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 =gsub("\\b(Consumo)", "consumo", DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 =gsub("\\b(Consumidores)", "consumo", DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 =gsub("\\b(consumidores)", "consumo", DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 =gsub("\\b(Consumidor)", "consumo", DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 =gsub("\\b(consumidor)", "consumo", DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 =gsub("\\b(Consumir)", "consumo", DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 =gsub("\\b(consumir)", "consumo", DB$DESCRI_PEDIDO1)
#DB$DESCRI_PEDIDO1 =gsub("\\b(http)>", "", DB$DESCRI_PEDIDO1)
DB$DESCRI_PEDIDO1 =tolower(DB$DESCRI_PEDIDO1)
#View(DB$DESCRI_PEDIDO1)
```

#### Frequência de palavras por diretoria
```{r}
diretoria_palavras_stem3 <- DB %>%
  unnest_tokens(palavra, DESCRI_PEDIDO1) %>%
  count(DIRETORIA, palavra, sort = TRUE) %>%
  ungroup()
```

#### Filtrando um pedaço de texto
```yaml
DB %>%
  filter(str_detect(DESCRI_PEDIDO1, "leiloes")) %>%
  select(DESCRI_PEDIDO1) %>%
  head()
```


Comparação do texto original c/ os 2 algoritmos e o final implementados após diferentes **stemmings**
```{r}
DB$DESCRI_PEDIDO[227]
ptstem(DB$DESCRI_PEDIDO[227])
rslp(DB$DESCRI_PEDIDO[227])
DB$DESCRI_PEDIDO1[227]
```


```{r}
DB$DESCRI_PEDIDO[350]
ptstem(DB$DESCRI_PEDIDO[350])
rslp(DB$DESCRI_PEDIDO[350])
DB$DESCRI_PEDIDO1[350]
```


##### Figura4: Termos mais relevantes por diretoria pela estatística **tf_idf**, após **stemming** porém ainda com **stop words**
Vamos, agora, plotar as quinze palavras mais relevantes de acordo com a estatística __tf_idf__, por diretoria
```{r, fig.width=9, fig.height=7}
plot_diretoria_palavras_stem <- diretoria_palavras_stem3 %>%
  bind_tf_idf(palavra, DIRETORIA, n) %>%
  arrange(desc(tf_idf)) %>%
  mutate(palavra = factor(palavra, levels = rev(unique(palavra)))) %>%
  mutate(DIRETORIA = factor(DIRETORIA, levels = c("DEA","DEE","OUTROS")))
#View(head(plot_diretoria_palavras))
#jpeg("02_freq_palavras_dir.jpeg")
plot_diretoria_palavras_stem %>%
  group_by(DIRETORIA) %>%
  top_n(4, tf_idf) %>%
  ungroup() %>%
  mutate(palavra = reorder(palavra, tf_idf)) %>%
  ggplot(aes(palavra, tf_idf, fill = DIRETORIA)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "tf-idf") +
  facet_wrap(~DIRETORIA, ncol = 2, scales = "free") +
  coord_flip() + 
  scale_y_continuous(labels=gcomma)
#dev.off()
```


### Stopwords
Com o arquivo de **stop words** previamente inserido vamos, primeiramente, transforma-lo em um data_frame a fim de futuramente utilizá-lo para extrair do texto palavras em comum.

#### Freq. de palavras sem **stopwords** por diretoria
```{r}
mystopwords <- data_frame(palavra = stopwords_pt)
diretoria_palavras_noSTOP <- anti_join(diretoria_palavras_stem3, mystopwords, 
                                       by = "palavra")
```

##### Figura5: Termos mais relevantes por diretoria pela estatística **tf_idf**, após **stemming** e sem **stop words**
Sim, a remoção de **stop words** não alterou em nada a ordem das 4 palavras mais relevantes de acordo com a estatística.
```{r 03_freq_palavras_dir_nostop, fig.width=9, fig.height=7}
#diretoria_palavras_noSTOP_noSTOP
plot_diretoria_palavras_noSTOP <- diretoria_palavras_noSTOP %>%
  bind_tf_idf(palavra, DIRETORIA, n) %>%
  arrange(desc(tf_idf)) %>%
  mutate(word = factor(palavra, levels = rev(unique(palavra)))) %>%
  mutate(DIRETORIA = factor(DIRETORIA, levels = c("DEA","DEE","OUTROS")))
#plot_diretoria_palavras_noSTOP
#windows.options(width=10, height=10)
#jpeg("03_freq_palavras_dir_nostop.jpeg")
plot_diretoria_palavras_noSTOP %>%
  group_by(DIRETORIA) %>%
  top_n(4, tf_idf) %>%
  ungroup() %>%
  mutate(palavra = reorder(palavra, tf_idf)) %>%
  ggplot(aes(palavra, tf_idf, fill = DIRETORIA)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "tf-idf") +
  facet_wrap(~DIRETORIA, ncol = 2, scales = "free") +
  coord_flip() + 
  scale_y_continuous(labels=gcomma)
#dev.off()
```

##### Wordcloud2 - DEE
```yaml
set.seed(6423)
plot_diretoria_palavras_noSTOP %>%
  filter(DIRETORIA == "DEE") %>%
  select(word = palavra, freq = tf_idf) %>%
  mutate(word = as.factor(word)) %>%
  #top_n(150, freq) %>%
  as.data.frame() %>%
  wordcloud2(shuffle = TRUE, color = "random-dark", shape = "circle", size = 1.10)
```

```{r, out.width = "400px",echo = FALSE, eval = TRUE, message=FALSE, include = TRUE}
wordcloud2DEE = "IMAGENS/WORDCLOUDS/01.ONEGRAM_wordcloud2_DEE01.png"
knitr::include_graphics(paste0(PATH,wordcloud2DEE))
```

##### Wordcloud2 - DEA
```yaml
set.seed(6423)
plot_diretoria_palavras_noSTOP %>%
  filter(DIRETORIA == "DEA") %>%
  select(word = palavra, freq = tf_idf) %>%
  mutate(word = as.factor(word)) %>%
  #top_n(150, freq) %>%
  as.data.frame() %>%
  wordcloud2(shuffle = TRUE, color = "random-dark", shape = "circle", size = .25)
```

```{r, out.width = "400px",echo = FALSE, eval = TRUE, message=FALSE, include = TRUE}
wordcloud2DEA = "IMAGENS/WORDCLOUDS/01.ONEGRAM_wordcloud2_DEA01.png"
knitr::include_graphics(paste0(PATH,wordcloud2DEA))
```

##### Wordcloud2 - OUTROS
```yaml
set.seed(6423)
plot_diretoria_palavras_noSTOP %>%
  filter(DIRETORIA == "OUTROS") %>%
  select(word = palavra, freq = tf_idf) %>%
  mutate(word = as.factor(word)) %>%
  #top_n(150, freq) %>%
  as.data.frame() %>%
  wordcloud2(shuffle = TRUE, color = "random-dark", shape = "circle", size = 0.35)
```

```{r, out.width = "400px",echo = FALSE, eval = TRUE, message=FALSE, include = TRUE}
wordcloud2OUTROS = "IMAGENS/WORDCLOUDS/01.ONEGRAM_wordcloud2_OUTROS01.png"
knitr::include_graphics(paste0(PATH,wordcloud2OUTROS))
```

#### Comparação de frequências dois a dois (sem stopwords e com stemming)
Vamos agora comparar a frequência de palavras entre diretorias. Antes disso, vamos criar documentos de texto no formato tidy separadamente para cada uma das 3 cateorias: _DEA_, _DEE_ e _OUTROS_.

```{r, child="03_1_compara2a2.Rmd"}

```

