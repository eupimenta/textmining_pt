# Modelagem 2 - Support Vector Machine (SVM){.tabset .tabset-fade .tabset-pills}
<!-- https://www.youtube.com/watch?v=pS5gXENd3a4 -->

Inicialmente o modelo SVM terá como premissa as mesmas variáveis utilizadas e preparadas anteriormente no modelo Final do RF.

## Ajuste do Modelo - Escolha do Kernel

_Ajustando o SVM_
```{r}
library(e1071)
set.seed(093180)
svm_01 <- svm(WR_Grp~.,data = train2,)
#svm_01; #attributes(svm_01)
#svm_01$nSV
summary(svm_01)
plot(svm_01, data = train2, num_voted_users~duration, 
     slice = list(title_year = 3, gross = 4))
plot(svm_01, data = train2, duration~num_voted_users, 
     slice = list(num_user_for_reviews = 3, gross = 4))
```

_Matriz de Confusão e Erro de Classificação (Missclassification Error)_
```{r}
pred.svm1 = predict(svm_01, train2)
(tab.svm1 = table(Predito = pred.svm1, Real = train2$WR_Grp))
(erro.kernelRAD = 1 - sum(diag(tab.svm1))/sum(tab.svm1))
```

```{r, echo = FALSE, eval = TRUE, message=FALSE, include = FALSE}
cat(paste0("Ou seja, usando o modelo de classificação para 2 categorias no SVM: [0, 6.5); e 6.5, 10]; E SVM-Kernel do tipo RADIAL, o modelo tem um erro de classificação aproximado em ", round(erro.kernelRAD*100,2), "%"))
```

Ajustando SVM com kernel Linear
```{r}
library(e1071)
set.seed(093180)
svm_02 <- svm(WR_Grp~.,data = train2, kernel = "linear")
summary(svm_02)
plot(svm_02, data = train2, num_voted_users~duration, 
     slice = list(title_year = 3, gross = 4))
plot(svm_02, data = train2, duration~num_voted_users, 
     slice = list(num_user_for_reviews = 3, gross = 4))
```

Temos que as seguintes matriz de confusão e erro de classificação para SVM com kernel Linear
```{r}
pred.svm2 = predict(svm_02, train2)
(tab.svm2 = table(Predito = pred.svm2, Real = train2$WR_Grp))
(erro.kernelLIN = 1 - sum(diag(tab.svm2))/sum(tab.svm2))
```

```{r, echo = FALSE, eval = TRUE, message=FALSE, include = FALSE}
cat(paste0("Logo, sando o modelo de classificação para 2 categorias no SVM: [0, 6.5); e 6.5, 10]; E SVM-Kernel do tipo LINEAR, o modelo tem um erro de classificação aproximado em ", round(erro.kernelLIN*100,2), "%."))
```

```{r, echo = FALSE, eval = TRUE, message=FALSE, include = FALSE}
cat(paste0("Ou seja, o uso do kernel Linear no ajuste do SVM aumenta o erro de classificação em cerca de ", round((erro.kernelLIN - erro.kernelRAD)*100,2),"% em relação ao uso do kernel Radial."))
```

Ajustando SVM com kernel Polinomial
```{r}
library(e1071)
set.seed(093180)
svm_03 <- svm(WR_Grp~.,data = train2, kernel = "polynomial", cost=16, epsilon=0)
summary(svm_03)
plot(svm_03, data = train2, num_voted_users~duration, 
     slice = list(title_year = 3, gross = 4))
plot(svm_03, data = train2, duration~num_voted_users, 
     slice = list(num_user_for_reviews = 3, gross = 4))
```

Temos que as seguintes matriz de confusão e erro de classificação para SVM com kernel Polynomial
```{r}
pred.svm3 = predict(svm_03, train2)
(tab.svm3 = table(Predito = pred.svm3, Real = train2$WR_Grp))
(erro.kernelPOLY = 1 - sum(diag(tab.svm3))/sum(tab.svm3))
```

```{r, echo = FALSE, eval = TRUE, message=FALSE, include = FALSE}
cat(paste0("Logo, sando o modelo de classificação para 2 categorias no SVM: [0, 6.5); e 6.5, 10]; E SVM-Kernel do tipo POLINOMIAL, o modelo tem um erro de classificação aproximado em ", round(erro.kernelPOLY*100,2), "%."))
```

```{r, echo = FALSE, eval = TRUE, message=FALSE, include = FALSE}
cat(paste0("Ou seja, o uso do kernel Polinomial no ajuste do SVM aumenta o erro de classificação em cerca de ", round((erro.kernelPOLY - erro.kernelRAD)*100,2),"% em relação ao uso do kernel Radial."))
```


Ajustando SVM com kernel Sigmoidal
```{r}
library(e1071)
set.seed(093180)
svm_04 <- svm(WR_Grp~.,data = train2, kernel = "sigmoid", cost=16, epsilon=0)
summary(svm_04)
plot(svm_04, data = train2, num_voted_users~duration, 
     slice = list(title_year = 3, gross = 4))
plot(svm_04, data = train2, duration~num_voted_users, 
     slice = list(num_user_for_reviews = 3, gross = 4))
```

Temos que as seguintes matriz de confusão e erro de classificação para SVM com kernel Sigmoid
```{r}
pred.svm4 = predict(svm_04, train2)
(tab.svm4 = table(Predito = pred.svm4, Real = train2$WR_Grp))
(erro.kernelSIGMOID = 1 - sum(diag(tab.svm4))/sum(tab.svm4))
```

```{r, echo = FALSE, eval = TRUE, message=FALSE, include = FALSE}
cat(paste0("Logo, sando o modelo de classificação para 2 categorias no SVM: [0, 6.5); e 6.5, 10]; E SVM-Kernel do tipo SIGMOID, o modelo tem um erro de classificação aproximado em ", round(erro.kernelSIGMOID*100,2), "%."))
```

```{r, echo = FALSE, eval = TRUE, message=FALSE, include = FALSE}
cat(paste0("Ou seja, o uso do kernel Sigmoid no ajuste do SVM aumenta o erro de classificação em cerca de ", round((erro.kernelSIGMOID - erro.kernelRAD)*100,2),"% em relação ao uso do kernel Radial."))
```
```{r, echo = FALSE, eval = TRUE, message=FALSE, include = FALSE}
cat(paste0("Definimos, portanto, que o modelo ajustado terá kernel Radial com erro de classificação aproximado de ", round(erro.kernelRAD*100,2),"%"))
```

É dificil a visualização no svm plot, por conter muitas variáveis, porém o mesmo plot para um modelo utilizando apenas as duas variáveis mais influentes no random forest (num_voted_users  e budget) embora gere uma visualização mais facilitada, tem uma classificação menos eficiente.
```{r}
library(e1071)
set.seed(093180)
svm_simp <- svm(WR_Grp~ num_voted_users +budget  ,data = train2, kernel = "polynomial", cost=16, epsilon=0)
summary(svm_simp)
plot(svm_simp, data = train2, num_voted_users~budget, 
     slice = list(title_year = 3, gross = 4))
```

Temos que as seguintes matriz de confusão e erro de classificação para SVM com kernel Polynomial
```{r}
pred.svms = predict(svm_simp, train2)
(tab.svms = table(Predito = pred.svms, Real = train2$WR_Grp))
(erro.kernelPOLYs = 1 - sum(diag(tab.svms))/sum(tab.svms))
```

## Tunning do Modelo

_Tunning ou Hypperparameter Optimization_
Este passo é importante para auxiliar a selecionar o melhor modelo.
`epsilon: 0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0`
`cost: 4, 8, 16, 32, 64, 128, 256, 512`
```yaml
ranges = list(epsilon = seq(0,1,.1), cost = 2^(2:9))
set.seed(123)
tmodel = tune(method = svm, WR_Grp ~ ., data = train2,
              ranges = ranges)
plot(tmodel)
summary(tmodel)
```

```yaml
> summary(tmodel)

Parameter tuning of ‘svm’:

- sampling method: 10-fold cross validation 

- best parameters:
 epsilon cost
       0   16

- best performance: 0.2073372 

- Detailed performance results:
   epsilon cost     error dispersion
1      0.0    4 0.2159598 0.02054510
2      0.1    4 0.2159598 0.02054510
3      0.2    4 0.2159598 0.02054510
4      0.3    4 0.2159598 0.02054510
5      0.4    4 0.2159598 0.02054510
6      0.5    4 0.2159598 0.02054510
7      0.6    4 0.2159598 0.02054510
8      0.7    4 0.2159598 0.02054510
9      0.8    4 0.2159598 0.02054510
10     0.9    4 0.2159598 0.02054510
11     1.0    4 0.2159598 0.02054510
12     0.0    8 0.2114626 0.02161040
13     0.1    8 0.2114626 0.02161040
14     0.2    8 0.2114626 0.02161040
15     0.3    8 0.2114626 0.02161040
16     0.4    8 0.2114626 0.02161040
17     0.5    8 0.2114626 0.02161040
18     0.6    8 0.2114626 0.02161040
19     0.7    8 0.2114626 0.02161040
20     0.8    8 0.2114626 0.02161040
21     0.9    8 0.2114626 0.02161040
22     1.0    8 0.2114626 0.02161040
23     0.0   16 0.2073372 0.01888178
24     0.1   16 0.2073372 0.01888178
25     0.2   16 0.2073372 0.01888178
26     0.3   16 0.2073372 0.01888178
27     0.4   16 0.2073372 0.01888178
28     0.5   16 0.2073372 0.01888178
29     0.6   16 0.2073372 0.01888178
30     0.7   16 0.2073372 0.01888178
31     0.8   16 0.2073372 0.01888178
32     0.9   16 0.2073372 0.01888178
33     1.0   16 0.2073372 0.01888178
34     0.0   32 0.2095942 0.01475664
35     0.1   32 0.2095942 0.01475664
36     0.2   32 0.2095942 0.01475664
37     0.3   32 0.2095942 0.01475664
38     0.4   32 0.2095942 0.01475664
39     0.5   32 0.2095942 0.01475664
40     0.6   32 0.2095942 0.01475664
41     0.7   32 0.2095942 0.01475664
42     0.8   32 0.2095942 0.01475664
43     0.9   32 0.2095942 0.01475664
44     1.0   32 0.2095942 0.01475664
45     0.0   64 0.2125862 0.02271235
46     0.1   64 0.2125862 0.02271235
47     0.2   64 0.2125862 0.02271235
48     0.3   64 0.2125862 0.02271235
49     0.4   64 0.2125862 0.02271235
50     0.5   64 0.2125862 0.02271235
51     0.6   64 0.2125862 0.02271235
52     0.7   64 0.2125862 0.02271235
53     0.8   64 0.2125862 0.02271235
54     0.9   64 0.2125862 0.02271235
55     1.0   64 0.2125862 0.02271235
56     0.0  128 0.2148264 0.03043428
57     0.1  128 0.2148264 0.03043428
58     0.2  128 0.2148264 0.03043428
59     0.3  128 0.2148264 0.03043428
60     0.4  128 0.2148264 0.03043428
61     0.5  128 0.2148264 0.03043428
62     0.6  128 0.2148264 0.03043428
63     0.7  128 0.2148264 0.03043428
64     0.8  128 0.2148264 0.03043428
65     0.9  128 0.2148264 0.03043428
66     1.0  128 0.2148264 0.03043428
67     0.0  256 0.2253358 0.03007258
68     0.1  256 0.2253358 0.03007258
69     0.2  256 0.2253358 0.03007258
70     0.3  256 0.2253358 0.03007258
71     0.4  256 0.2253358 0.03007258
72     0.5  256 0.2253358 0.03007258
73     0.6  256 0.2253358 0.03007258
74     0.7  256 0.2253358 0.03007258
75     0.8  256 0.2253358 0.03007258
76     0.9  256 0.2253358 0.03007258
77     1.0  256 0.2253358 0.03007258
78     0.0  512 0.2298232 0.03273436
79     0.1  512 0.2298232 0.03273436
80     0.2  512 0.2298232 0.03273436
81     0.3  512 0.2298232 0.03273436
82     0.4  512 0.2298232 0.03273436
83     0.5  512 0.2298232 0.03273436
84     0.6  512 0.2298232 0.03273436
85     0.7  512 0.2298232 0.03273436
86     0.8  512 0.2298232 0.03273436
87     0.9  512 0.2298232 0.03273436
88     1.0  512 0.2298232 0.03273436
```


## Best Model (Melhor Modelo)

Gráfico de performance do SVM.
Onde a coloração em azul mais forte (escuro) aponta menor erro de classificação
```{r, out.width = "400px",echo = FALSE, eval = TRUE, message=FALSE, include = TRUE, fig.align="center"}
DIR1 = "E:/2018-2/IC/PROJETOS/Classificador-IMDB/RECOMMENDER-IMDB/"
knitr::include_graphics(paste0(DIR1,"IMG/PLOTS/Tuning01-SVM.png"))
```

```yaml
mymodel = tmodel$best.model
summary(mymodel)
```

```yaml
> summary(mymodel

Call:
best.tune(method = svm, train.x = WR_Grp ~ ., data = train2, ranges = ranges)


Parameters:
   SVM-Type:  C-classification 
 SVM-Kernel:  radial 
       cost:  16 
      gamma:  0.07692308 

Number of Support Vectors:  1308

 ( 646 662 )


Number of Classes:  2 

Levels: 
 [0, 6.5) 6.5, 10]

```


_Matriz de Confusão e Erro de Classificação (Missclassification Error)_
```yaml
pred.bestsvm = predict(mymodel, train2)
(tab.bestsvm = table(Predito = pred.bestsvm, Real = train2$WR_Grp))
(erro.kernelRAD.BEST = 1 - sum(diag(tab.bestsvm))/sum(tab.bestsvm))
```

```yaml
(tab.bestsvm = table(Predito = pred.bestsvm, Real = train2$WR_Grp))
          Real
Predito    [0, 6.5) 6.5, 10]
  [0, 6.5)     1172      236
  6.5, 10]      156     1103
> (erro.kernelRAD.BEST = 1 - sum(diag(tab.bestsvm))/sum(tab.bestsvm))
[1] 0.1469816
```

```yaml
plot(mymodel, data = train2, num_voted_users~duration, 
     slice = list(title_year = 3, gross = 4))
plot(mymodel, data = train2, duration~num_voted_users, 
     slice = list(num_user_for_reviews = 3, gross = 4))
```


Gráf. de classificação do SVM
```{r, out.width = "400px",echo = FALSE, eval = TRUE, message=FALSE, include = TRUE, fig.align="center"}
DIR1 = "E:/2018-2/IC/PROJETOS/Classificador-IMDB/RECOMMENDER-IMDB/"
knitr::include_graphics(paste0(DIR1,"IMG/PLOTS/classifica1.png"))
```

```{r, out.width = "400px",echo = FALSE, eval = TRUE, message=FALSE, include = TRUE, fig.align="center"}
DIR1 = "E:/2018-2/IC/PROJETOS/Classificador-IMDB/RECOMMENDER-IMDB/"
knitr::include_graphics(paste0(DIR1,"IMG/PLOTS/classifica2.png"))
```
