---
title: "Recomendador de Filmes"
subtitle: "Movie Recommender: Collaborative Filtering, Shiny - IMDB - Internet Movie DataBases"
author: 
- name: Ewerson C. Pimenta 
  email: pimentaeu@yahoo.com
- name: Marcos Antônio E. de Oliveira
  email: marcoseuzbio@gmail.com
date: "`r format(Sys.time(), 'Rio de Janeiro, %d de %B de %Y')`"
output:
  html_document:
    number_sections: true
    toc: true
    fig_width: 10
    code_folding: hide
    fig_height: 4.5
    theme: cosmo
    highlight: tango
csl: apa.csl
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---
  
  
  
  <!-- highlight: tango pygments kate monochrome zenburn haddock textmate -->
  <!-- theme: cerulean, journal, flatly, readable, spacelab, united, cosmo, lumen, paper, sandston, simplex, yeti -->
  
  <!----------  INÍCIO CONFIG  ---------->
  
```{r INSTALPACK, echo = FALSE, eval = TRUE, message=FALSE, include = FALSE}
list.of.packages <- c("arules","dplyr","HardyWeinberg","cdparcoord", "knitr", "knitLatex", "kableExtra", "tidyverse", "tidyverse", "cdparcoord", "cowplot", "ggpubr", "gridExtra", "stringi", "cluster", "factoextra", "cluster", "randomForest", "rpart.plot", "DT", "keras", "carat")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
remove(list.of.packages, new.packages)
```

```{r READPACK, echo = FALSE, eval = TRUE, message=FALSE, include = FALSE}
#library(gridExtra)          # Organiza e posiciona múltiplas tables e/ou plots
library(tidyverse)
library(highcharter)
library(knitr)
library(kableExtra)
library(DT)
library(randomForest)
library(rpart)
library(rpart.plot)
library(carat)
```


```{r READMETADATA, echo = FALSE, eval = TRUE, message=FALSE, include = FALSE}
# Lendo o arquivo de dados
#RECOMMEND.METADATA = readxl::read_xlsx(path = "E:/2018-2/IC/PROJETOS/PROJ2/RECOMMENDER-IMDB/DB/IMDB.xlsx", sheet = 1, )
RECOMMEND.METADATA = read.csv2(file = "E:/2018-2/IC/PROJETOS/PROJ2/RECOMMENDER-IMDB/DB/movie_metadata.csv", 
                               sep=',', header = TRUE, encoding = 'UTF-8')
db = RECOMMEND.METADATA
#View(db[1:50,])
#class(db)
#getwd()
```

  <!----------  INÍCIO CONFIG  ---------->
  
# Introdução

  Frequentemente utilizamos serviços de recomendação seja por plataformas como *Netflix, Mercado Livre, OLX* dentre outros. O conjunto de dados explanados a seguir foram extraídos da plataforma Kaggle e são referentes ao catálogo de filmes da plataforma IMDB, o intuito aqui é criar um sistema de recomendação orientado a dados do catálogo e avaliação de filmes do IMDB.

  Esse projeto irá explorar o conjunto de dados e gerar insights, e aplicar o algoritmo de Random Forest (baseado na clusterização de Breiman).


```{r, out.width = "400px",echo = FALSE, eval = TRUE, message=FALSE, include = TRUE}
#knitr::include_graphics("D:/2018-2/IC/PROJETOS/PROJ2/RECOMMENDER-IMDB/IMG/popcorn.jpg")
knitr::include_graphics("E:/2018-2/IC/PROJETOS/PROJ2/RECOMMENDER-IMDB/IMG/popcorn.jpg")
```

-------------------------------------

__Pacotes e Leitura__

Alguns pacotes R utilizados nessa rotina
```yaml
library(tidyverse)          # Manipulação de banco de dados e análise exploratória
library(highcharter)        # Highchart gráficos usando htmlwidgets (renderiza HTML via código R Markdown)
library(DT)                 # Tabelas: datatable()
library(knitr)
library(kableExtra)
library(rpart.plot)
library(randomForest)
```

```yaml
RECOMEND.METADATA = readxl::read_xlsx(path = ".../DB/IMDB.xlsx", sheet = 1)
db = RECOMEND.METADATA
```

# Banco de Dados{.tabset .tabset-fade .tabset-pills}

  O conjunto de dados utilizado foi o de título *IMDB 5000* extraído da plataforma [kaggle](https://www.kaggle.com/). As informações contidas no banco foram catalogadas de filmes publicados ao longo de 100 anos em 66 países (entre 1916 e 2016) da plataforma IMDB - Internet Movie DataBases, o Arquivo original contém 5044 filmes (observações) e 28 variáveis descritas a seguir.
  

```{r, echo = FALSE, eval = TRUE, message=FALSE, include = TRUE}
INFO = c("movie_title","Title of the Movie","duration","Duration in minutes","director_name","Name of the Director of the Movie","director_facebook_likes","Number of likes of the Director on his Facebook Page",
        "actor_1_name","Primary actor starring in the movie","actor_1_facebook_likes","Number of likes of the Actor_1 on his/her Facebook Page","actor_2_name","Other actor starring in the movie","actor_2_facebook_likes","Number of likes of the Actor_2 on his/her Facebook Page",
        "actor_3_name","Other actor starring in the movie","actor_3_facebook_likes","Number of likes of the Actor_3 on his/her Facebook Page","num_user_for_reviews","Number of users who gave a review","num_critic_for_reviews","Number of critical reviews on imdb",
        "num_voted_users","Number of people who voted for the movie","cast_total_facebook_likes","Total number of facebook likes of the entire cast of the movie","movie_facebook_likes","Number of Facebook likes in the movie page","plot_keywords","Keywords describing the movie plot",
        "facenumber_in_poster","Number of the actor who featured in the movie poster","color","Film colorization. ‘Black and White’ or ‘Color’","genres","Film categorization like ‘Animation’, ‘Comedy’, ‘Romance’, ‘Horror’, ‘Sci-Fi’, ‘Action’, ‘Family’","title_year","The year in which the movie is released (1916:2016)",
        "language","English, Arabic, Chinese, French, German, Danish, Italian, Japanese etc","country","Country where the movie is produced","content_rating","Content rating of the movie","aspect_ratio","Aspect ratio the movie was made in","movie_imdb_link","IMDB link of the movie",
        "gross","Gross earnings of the movie in Dollars","budget","Budget of the movie in Dollars","imdb_score", "IMDB Score of the movie on IMDB")
# Cria matriz de INFO
INFO = as.data.frame(matrix(INFO,byrow = T, ncol = 2))
colnames(INFO) = c("Variables", "Description")
datatable(INFO,  
          options = list(searchin = TRUE, pageLength = 5))
remove(INFO)
```


*Os dados em questão são públicos e disponíveis para download clicando [AQUI](https://data.world/data-society/imdb-5000-movie-dataset) ou [AQUI](https://www.kaggle.com/carolzhangdc/analyze-imdb-score-with-data-mining-algorithms/data).* 


# Análise Exploratória dos dados{.tabset .tabset-fade .tabset-pills}

```{r, echo = FALSE, eval = TRUE, message=FALSE, include = TRUE}
set.seed(123465)
amostra1 = sample(x = 1:dim(db)[1], size = 35, replace = FALSE)
t1 = db[amostra1,]
datatable(t1,  rownames = amostra1,
          options = list(searchin = TRUE, scrollX = TRUE, pageLength = 5)); remove(t1)
```

          
## Estrutura dos dados
```{r, echo = FALSE, eval = TRUE, message=FALSE, include = TRUE}
cat("O banco de dados possui", dim(db)[1], "observações e", dim(db)[2], "variáveis")
```


Excluindo algumas variáveis que não serão utilizadas.

- (1) As variáveis  *color*, *director_name*, *language*, *country*, *content_rating*, em especial, foram removidas uma vez que estas não se mostraram importantes no algoritmo de importância do Random Forest de Breiman.

- (2) Já as variáveis *director_facebook_likes*, *actor_3_facebook_likes*, *actor_2_name*, *actor_1_facebook_likes*, *actor_1_name*, *actor_3_name,-facenumber_in_poster*, *actor_2_facebook_likes*, *movie_imdb_link* foram extraídas de forma determinística por escolha dos autores deste.

O motivo de remover as variáveis em (1) é devido à tentativa de reduzir o número de missing na base de dados. no passo 3.1 de Tratamento de NA's.
```{r}
#db=RECOMMEND.METADATA
db = db %>% select(- director_facebook_likes, -actor_3_facebook_likes, -actor_2_name, -actor_1_facebook_likes, -actor_1_name, -actor_3_name,-facenumber_in_poster, -actor_2_facebook_likes, -color, -director_name, -language, -country, -content_rating, -movie_imdb_link)
```

```{r, echo = FALSE, eval = TRUE, message=FALSE, include = TRUE}
cat("O banco de dados agora possui", dim(db)[2], "variáveis. Ou seja, foram removidas ",dim(RECOMMEND.METADATA)[2]-dim(db)[2], "variáveis no passo anterior.")
```


Estrutura dos dados
```{r}
glimpse(db) #str(db)
```


## Transformação de variáveis 

Transformando as variáveis `imdb_score` e `aspect_ratio` em numéricas
```{r}
db$imdb_score = as.numeric(as.character(db$imdb_score))
db$aspect_ratio = as.numeric(as.character(db$aspect_ratio))
```


```{r}
hc1 = hchart(db$imdb_score, color = "#e8bb0b", name = "imdb_score") %>% 
        hc_title(text = "Histograma dos votos na plataforma IMDB") %>%
        hc_exporting(enabled = TRUE, filename = "Fig1-Pimenta"); hc1
```

```{r}
hc2 = hchart(db$num_voted_users, color = "#786eea", name = "imdb_num_votos") %>% 
        hc_title(text = "Histograma dos número de votos na plataforma IMDB") %>%
        hc_exporting(enabled = TRUE, filename = "Fig2-Pimenta"); hc2
```

Criando uma função para cálculo da moda
```{r}
Moda <- function(x) {
     ux <- unique(x)
     ux[which.max(tabulate(match(x, ux)))]
}
```


```{r, echo = FALSE, eval = TRUE, message=FALSE, include = TRUE}
cat("Média, moda e mediana da variável imdb_score são, respectivamente,",round(mean(db$imdb_score, na.rm = TRUE),2), Moda(db$imdb_score),median(db$imdb_score, na.rm = TRUE))
```

Extraindo valores da variável gênero e transformando em dummies
```{r, message=FALSE}
gg <- as.character(db$genres)

#t <- unlist(strsplit(gg[1],split = "\\|"))
tem1 <- data.frame() 
for(i in 1:length(gg)){
        tem <- tem1
        t <- unlist(strsplit(gg[i],split = "\\|"))
        temp <- data.frame(t)
        tem1 <- rbind(tem,temp)
}

Gen <- unique(tem1)
cat("Existem", dim(Gen)[1], "valores de gêneros de filme únicos no banco de dados.")
Genname <- as.character(Gen$t); Genname = gsub("-", "_", Genname)

fe <- matrix(data = 0, nrow = length(gg), ncol = length(Genname))
fe <- data.frame(fe); colnames(fe) <- Genname

for(i in 1:length(gg)){
        for(j in 1:length(Genname)){
                g <- grepl(Genname[j], gg[i])
                if(g == TRUE){
                        fe[i, j] <- 1        
                }
        }
}

NumGen = as_tibble(rbind(apply(fe,2,sum)))
NumGen = gather(NumGen, key = "variables", value = "num_gender")
NumGen = NumGen[order(NumGen$num_gender, decreasing = TRUE), ]


hc3 <- highchart() %>%
  hc_add_series(data = NumGen$num_gender, 
                type = "bar",
                name = "# de filmes",
                showInLegend = FALSE,
                tooltip = list(valueDecimals = 0, valuePrefix = "", valueSuffix = ""), color="blue") %>%
  hc_yAxis(title = list(text = "Quantitativo de filmes"), 
           allowDecimals = TRUE, max = (max(NumGen$num_gender)+103),
           labels = list(format = "{value}")) %>%
  hc_xAxis(title = list(text = "Gênero de filme"),
           categories = NumGen$variables,
           tickmarkPlacement = "on",
           opposite = FALSE) %>%
  hc_title(text = "Quantitativo de filmes por gênero",
           style = list(fontWeight = "bold")) %>% 
  hc_subtitle(text = paste("")) %>%
      hc_tooltip(valueDecimals = 2,
                 pointFormat = "{point.y} filmes")%>%
                 #pointFormat = "Variável: {point.x} <br> Missing: {point.y}") 
      hc_credits(enabled = TRUE, 
                 text = "Fonte: IMDB/KAGGLE. Elaboração: Ewerson Pimenta.",
                 style = list(fontSize = "10px")) %>%
  hc_exporting(enabled = TRUE, filename = "F3-filmes-genero-Pimenta")
#hc <- hc %>% 
#  hc_add_theme(hc_theme_darkunica())
hc3; remove(gg,t,tem, temp, tem1,Gen, g, i, j)
```

Unificando a base de dados com as novas variáveis de gêneros únicos descobertos.
```{r}
db1 = as_tibble(cbind(as.data.frame(db),fe))
```

```{r}
cat("Foram inseridas todas as", dim(fe)[2],"novas variáveis provenientes dos gêneros únicos descobertos no passo anterior.")
```

<!-- 
Extraindo valores da variável plot_keyword e transformando em dummies
```{r}
gg2 <- as.character(db1$plot_keywords)

t <- unlist(strsplit(gg2[1],split = "\\|"))

tem2 <- data.frame() 
for(i in 1:length(gg2)){
        tem <- tem2
        t <- unlist(strsplit(gg2[i],split = "\\|"))
        temp <- data.frame(t)
        tem2 <- rbind(tem,temp)
}

KeyWord <- unique(tem2)
KeyWord$t <- gsub(" ", "_", KeyWord$t)


cat("Existem", dim(KeyWord)[1], "palavras chaves (keyword) únicas no banco de dados.")
KeyWord <- as.character(KeyWord$t)

fe2 <- matrix(data = 0, nrow = length(gg2), ncol = length(KeyWord))
fe2 <- data.frame(fe2); colnames(fe2) <- KeyWord

for(i in 1:length(gg2)){
        for(j in 1:length(KeyWord)){
                g <- grepl(KeyWord[j], gg2[i])
                if(g == TRUE){
                        fe2[i, j] <- 1        
                }
        }
}

NumKW = as_tibble(rbind(apply(fe2,2,sum)))
NumKW = gather(NumKW, key = "variables", value = "num_keyword")
NumKW = NumKW[order(NumKW$num_keyword, decreasing = TRUE), ]


hc <- highchart() %>% 
  hc_title(text = "Treemap Palavras-Chaves (keyword)") %>% 
  hc_add_series(data = list.parse2(NumKW), type = "treemap", colorByPoint = TRUE) %>%
  hc_tooltip(crosshairs = TRUE, shared = TRUE, borderWidth = 5)
hc

# A IDEIA AQUI É DESENHAR UM WORDCLOUD
```
-->
## Tratamento de NA

Porcentagem de NA por variável
```{r}
db_miss <- db %>% summarise_all(funs(sum(is.na(.))/n()))
db_miss <- gather(db_miss, key = "variables", value = "percent_missing")
db_miss$percent_missing = 100*db_miss$percent_missing
db_miss = db_miss[order(db_miss$percent_missing, decreasing = TRUE), ]
#db_miss

hc4 <- highchart() %>%
  hc_add_series(data = db_miss$percent_missing, 
                type = "bar",
                name = "Porcentagem de missing",
                showInLegend = FALSE,
                tooltip = list(valueDecimals = 2, valuePrefix = "", valueSuffix = " %")) %>%
  hc_yAxis(title = list(text = "Porcentagem de missing"), 
           allowDecimals = TRUE, max = 20,
           labels = list(format = "{value}%")) %>%
  hc_xAxis(categories = db_miss$variables,
           tickmarkPlacement = "on",
           opposite = FALSE) %>%
  hc_title(text = "Porcentagem de missinig por variável",
           style = list(fontWeight = "bold")) %>% 
  hc_subtitle(text = paste("")) %>%
      hc_tooltip(valueDecimals = 2,
                 pointFormat = "Missing: {point.y}")%>%
                 #pointFormat = "Variável: {point.x} <br> Missing: {point.y}") 
      hc_credits(enabled = TRUE, 
                 text = "Fonte: IMDB/KAGGLE. Elaboração: Ewerson Pimenta.",
                 style = list(fontSize = "10px")) %>%
  hc_exporting(enabled = TRUE, filename = "Fig0-Pimenta")
#hc <- hc %>% 
#  hc_add_theme(hc_theme_darkunica())
hc4
```

Removendo todas as observações que contêm NA.
```{r}
db1 <- db1 %>% drop_na(gross, budget, aspect_ratio 
,title_year 
,num_critic_for_reviews, num_user_for_reviews)
#glimpse(db1)

db1 <- db1 %>% na.omit()
db1 <- db1 %>% drop_na()
```


```{r REMOVE_NA, echo = FALSE, eval = TRUE, message=FALSE, include = TRUE}
cat("O novo banco de dados, sem observações faltantes, possui", dim(db1)[1], "observações. Ou seja, no processo de remoção de valores faltantes foram perdidas", dim(db)[1]-dim(db1)[1], "observações.")
```


## Weighted Rating (WR) - IMDB_score


Um passo importante é penalizar a variável de escore `imdb_score` pelo [número de votos recebidos](https://help.imdb.com/article/imdb/track-movies-tv/faq-for-imdb-ratings/G67Y87TFYYP6TWAV#). Ver mais no estimador de [Shrinkage](https://stats.stackexchange.com/questions/6418/rating-system-taking-account-of-number-of-votes)


$WR = \frac{v}{v+m} \times R + \frac{m}{v+m} \times C$

Onde,

```{r}
R = as.numeric(db1$imdb_score)
v = as.numeric(db1$num_voted_users)
m = 7000
C = 6.5
db1$WR = (v/(v+m))*R + (m/(v+m))*C
```

* R = Escore médio dos votos para o título do filme dado pelos usuários do IMDB = (imdb_score)
* v = Número de usuários que votaram = (num_voted_users)
* m = Mínimo de votos requerido (atualmente 7.000)
* C = O escore médio de todos os 3766 filmes (atualmente 6,5)

```{r}
summary(db1$imdb_score)
summary(db1$WR)
sd(db1$imdb_score)
sd(db1$WR)
```

Selecionando uma amostra aleatória (a.a.) de tamanho $n=800$ e representando em um gráfico de dispersão com valores reais vs ajustados.
```{r}
set.seed(123654)
amostra0 = sample(x = 1:dim(db1)[1], size = 800, replace = FALSE)
dbX = db1[amostra0,] %>% 
  select(movie_title,num_voted_users,imdb_score, WR)
  
dss <- map(c("cross"), function(s){
  
  x <- as.numeric(dbX$imdb_score)
  y <- as.numeric(dbX$WR)
  
  list(name = s,
       data = list_parse(data_frame(x, y)),
       marker = list(symbol = s, enabled = TRUE), lineColor = "#56667a")
  
})
#dss[[1]]$data[amostra1]

hc5 = highchart() %>% 
  hc_chart(type = "scatter", color = "#56667a") %>% 
  hc_title(text = "Score IMDB vs WR (calculado pelo estimador de Shrinkage)") %>%
  hc_subtitle(text = "800 filmes selecionados via amostra aleatória simples") %>%
  hc_xAxis(title = list(text = "x: imdb_score"), 
           allowDecimals = TRUE, labels = list(format = "{value}★")) %>%
  hc_yAxis(title = list(text = "y: WR (calibrado)"),
           allowDecimals = TRUE, labels = list(format = "{value}★")) %>%
  hc_exporting(enabled = TRUE, filename = "F3-Pimenta") %>%
  hc_add_series_list(dss); hc5; remove(dbX, dss)
```

Análise do cálculo de IMDB

- Para filmes com # de votos recebidos MENOR que 7mil (m: votos mínimos requeridos):  
    + imdb_score > 6,5: DECRESCIMENTO  
    + imdb_score < 6,5: CRESCIMENTO  


- Para filmes com # de votos recebidos MAIOR que 7mil (m: votos mínimos requeridos):  
    + imdb_score > 6,5: DECRESCIMENTO  
    + imdb_score < 6,5: CRESCIMENTO  


Ou seja, para os filmes catalogados com m muito inferior a 7mil o novo escore calibrado teve maior diferentça que aqueles superior a 7 mil. Além disso, quando scores são maiores que 6,5 o WR tende a cair, caso contrário o valor pode aumentar. Quanto maior o número de votos recebidos, menor a diferença do valor de IMDB_score e WR.

```{r}
set.seed(123654)
amostra2 = sample(x = 1:dim(db1)[1], size = 35, replace = FALSE)
db1[amostra2,] %>% 
  select(movie_title,num_voted_users,imdb_score, WR, movie_facebook_likes, budget) %>% 
  datatable(rownames = amostra2,options = list(searchin = TRUE, scrollX = TRUE, pageLength = 5))
```

## Visualizações Finais

Finalmente, segue uma a.a.da base de dados após limpeza e análise exploratória.
```{r}
set.seed(123851)
amostra3 = sample(x = 1:dim(db1)[1], size = 35, replace = FALSE)
db1[amostra3,] %>%
datatable(rownames = amostra3,options = list(searchin = TRUE, scrollX = TRUE, pageLength = 5))
```

Para os dados quantitativos a seguinte [Matriz de correlação](https://cran.r-project.org/web/packages/corrplot/vignettes/corrplot-intro.html)
```{r, out.width = "600px",echo = FALSE, eval = TRUE, message=FALSE, include = TRUE}
#knitr::include_graphics("D:/2018-2/IC/PROJETOS/PROJ2/RECOMMENDER-IMDB/IMG/popcorn.jpg")
knitr::include_graphics("E:/2018-2/IC/PROJETOS/PROJ2/RECOMMENDER-IMDB/IMG/PLOTS/3.Fig.Correlation.png")
```

 


------------------------------------------------------------------------------------------------

<!--
*https://www.kaggle.com/carolzhangdc/analyze-imdb-score-with-data-mining-algorithms*
*https://www.kaggle.com/philippsp/book-recommender-collaborative-filtering-shiny  *
*https://www.kaggle.com/pimentaeu/kernels/scripts/new?forkParentScriptVersionId=1563912*  
*https://philippsp.shinyapps.io/BookRecommendation/*
*https://www.kaggle.com/gaborfodor/kaggle-trends*
-->

# Modelagem{.tabset .tabset-fade .tabset-pills}


## Preparação de dados

__Transformação da variável contínua `WR`em categórica `WR_Grp`__  

Transformando a variável WR em fator, com as seguintes categorias:

- 0 a 4 ★
- de 4 a 6 ★
- de 6 a 8 ★
- de 8 a 10 ★

```{r}
movie = db1
Grp <- function(tn){
  tn = abs(tn)
    if (tn >= 0 & tn <= 4){
        return('0-4')
    }else if(tn > 4 & tn <= 6){
        return('de 4-6')
    }else if(tn > 6 & tn <= 8){
        return('de 6 a 8')
    }else if (tn > 8){
        return('de 8 a 10')
    }
}
# apply the Group function to the WR column
movie$WR_Grp <- sapply(movie$WR,Grp)
# set as factor the new column
movie$WR_Grp <- as.factor(movie$WR_Grp)
#View(head(movie))
table(movie$WR_Grp)

# apply the Group function to the WR column
imdb_score_Grp <- sapply(movie$imdb_score,Grp)
# set as factor the new column
imdb_score_Grp <- as.factor(imdb_score_Grp)
#View(head(movie))
table(imdb_score_Grp)
```

__Remoção de variáveis__
Remove as variáveis *imdb_score*, *genres*, *plot_keywords*, *movie_imdb_link* e *WR*.
```{r}
movie$imdb_score <- NULL
movie$genres <- NULL
movie$plot_keywords <- NULL
movie$movie_imdb_link <- NULL
movie$WR <- NULL
```


```{r}
glimpse(movie)
```


```{r}
cat("A base de dados que iremos trabalhar no modelo tem", dim(movie)[1] , "observações e ", dim(movie)[2]-1, "variáveis, sem contar a variável que contém os títulos dos filmes.")
```

<!--
Também removemos os rótulos dos filmes, mas, antes, armazenaremos os rótulos dos filmes na variável `filme` 
```{r}
filme <- movie$movie_title 
movie$movie_title <- NULL # We are not going to work here with text variables
```
-->

__Partição dos dados__

Particionando a base de dados em Treino e Teste, esses dois (Treino e Teste) também terão armazenos os nomes dos filmes selecionados via amostragem probabilística dos dados originais separadamente das bases de Treino e Teste.

Posteriormente, removemos os rótulos dos filmes nas bases Treino e Teste

```{r}
set.seed(9182345)
ind <- sample(2, nrow(movie), replace = T, prob = c(0.7, 0.3))
train <- movie[ind==1, -4]
test <- movie[ind==2, -4]
trainMovie <- movie[ind==1, 4]
testMovie <- movie[ind==2, 4]
```

Distribuição dos escores nas bases de treino e teste
```{r}
round(table(train$WR_Grp)/sum(table(train$WR_Grp))*100,2)
round(table(test$WR_Grp)/sum(table(test$WR_Grp))*100,2)
```



## Random Forest - Parte 1

__Descrição__
- Random Forest foi desenvolvido para agregar árvores de decisão (modelo de classificação);  
- Pode ser usado para modelo de classificação (p/ var. resposta categórica) ou regressão (no caso de haver variável resposta contínua);  
- Evita *overfitting*;  
- Permite trabalhar com um largo número de características de um conjunto de dados;  
- Auxilia na seleção de variáveis baseada em um algoritmo que calcula a importância por variável (assim, tendo conhecimento de quais variáveis são mais importantes, podemos usar essa informação para outros modelos de classificação);  
- User-friendly: apenas 2 parâmetros livres:  
    + Trees - ntrees, default 500 (Nº de árvores);
    + Variáveis selecionadas via amostragem aleatória candidatas à cada "split"  (quebra da árvore) - mtry, default $\sqrt{p}$ p/ classificação e $\frac{p}{3}$ p/ regressão (p: nº de features/variáveis);


__Passo-a-Passo__

É realizado em 3 passos:

- 1. Draw ntrees bootstrap samples;  
- 2. Para cada amostra via bootstrap, it grows un-puned tree by escolha da melhor quebra da árvore baseadi ba amostra aleatória do valor predito de mtry a cada nó da árvore;  
- 3. Faz classificação de novos valores usando a maioria de votos p/ classificação e usa a média p/ regressão baseada nas amostras de ntrees.

__Exemplo__

```{r, out.width = "400px",echo = FALSE, eval = TRUE, message=FALSE, include = TRUE}
#knitr::include_graphics("D:/2018-2/IC/PROJETOS/PROJ2/RECOMMENDER-IMDB/IMG/popcorn.jpg")
knitr::include_graphics("E:/2018-2/IC/PROJETOS/PROJ2/RECOMMENDER-IMDB/IMG/ntrees.png")
```

------------------------------------------------------

## Random Forest - Passo 2

Inicialmente utilizaremos o pacote `randomForest` que implmenta o algoritmo de Random Forest de Breiman (baseado na clusterização de Breiman, originalmente codificada em Fortran) que tem por finalidade classificar e criar regressão. Além disso, pode ser usado em um modelo não supervisionado para avaliar proximidades entre pontos. 

Estamos usando, a partir daqui, a base de treino.
```{r}
#library(randomForest)
#library(rpart)
#library(rpart.plot)
#rf <- randomForest(proximity = T,ntree = 38,do.trace = T,WR~.,data=training)
set.seed(9984512)
rf <- randomForest(WR_Grp~.,data=train)
rf
attributes(rf)
```

Olhando as 6 primeiras observações real X predito
```{r}
library(caret)
p1 <- predict(rf,train)
head(p1)
head(train$WR_Grp)
```

__Matriz de confusão__

```{r}
confusionMatrix(p1, train$WR_Grp)
```

```{r, out.width = "400px",echo = FALSE, eval = TRUE, message=FALSE, include = TRUE}
#knitr::include_graphics("D:/2018-2/IC/PROJETOS/PROJ2/RECOMMENDER-IMDB/IMG/popcorn.jpg")
knitr::include_graphics("E:/2018-2/IC/PROJETOS/PROJ2/RECOMMENDER-IMDB/IMG/CONF_Matrix.png")
```

Acurácia
```{r}
(17+600+1980+104)/dim(train)[1]
```

<!-- https://www.youtube.com/watch?v=dJclNIN-TPo -->

```{r}
RF_importance = randomForest::importance(rf)[order(randomForest::importance(rf)[,1], decreasing = TRUE), ]
knitr::kable(RF_importance)
```

```{r}
randomForest::varImpPlot(rf)
```

No passo a seguir, removeremos as variáveis  *Game_Show*, *Sci_Fi*, *Reality_TV*, *News* e *Film_Noir* uma vez que estas não se mostraram importantes no algoritmo.
```{r}
train1 = train %>% select(-Sci_Fi, -Game_Show, -Reality_TV, -News, -Short, -Film_Noir)
test1 = test %>% select(-Sci_Fi, -Game_Show, -Reality_TV, -News, -Short, -Film_Noir)
```


Assim, repetimos o algoritmo do Random Forest, ainda usando a base treino.

```{r}
set.seed(9984512)
rf1 <- randomForest(WR_Grp~.,data=train1)
rf1
RF_importance1 = randomForest::importance(rf1)[order(randomForest::importance(rf1)[,1], decreasing = TRUE), ]
```

```{r}
RF = as_tibble(data.frame(variables = names(RF_importance1), importance = RF_importance1))
rownames(RF) <- NULL

hc6 <- highchart() %>%
  hc_add_series(data = RF$importance, 
                type = "bar",
                name = "Importância",
                showInLegend = FALSE,
                tooltip = list(valueDecimals = 2, valuePrefix = "", valueSuffix = "")) %>%
  hc_yAxis(title = list(text = "Importãncia"), 
           allowDecimals = TRUE, max = 200,
           labels = list(format = "{value}")) %>%
  hc_xAxis(title = list(text = "Fatores"),
           categories = RF$variables,
           tickmarkPlacement = "on",
           opposite = FALSE) %>%
  hc_title(text = "Importância por fator - Random Forest",
           style = list(fontWeight = "bold")) %>% 
  hc_subtitle(text = paste("")) %>%
      hc_tooltip(valueDecimals = 2,
                 pointFormat = "Importância: {point.y}")%>%
                 #pointFormat = "Variável: {point.x} <br> Importância: {point.y}") 
      hc_credits(enabled = TRUE, 
                 text = "Fonte: IMDB/KAGGLE. Elaboração: Ewerson Pimenta.",
                 style = list(fontSize = "10px")) %>%
  hc_exporting(enabled = TRUE, filename = "F4-missing-Pimenta")
#hc <- hc %>% 
#  hc_add_theme(hc_theme_darkunica())
hc6
```

__Predição e matriz de confusão - train data__
```{r}
library(caret)
p1 <- predict(rf1,train1)
head(p1)
head(train1$WR_Grp)
confusionMatrix(p1, train1$WR_Grp)
```

__Predição e matriz de confusão - test data__
```{r}
p2 <- predict(rf1,test1)
head(p2)
head(test1$WR_Grp)
confusionMatrix(p2, test1$WR_Grp)
```


__Taxa de Erro - Random Forest__
```{r}
plot(rf1)
```

Tune mtry
```{r}
tuneRF(train[])
```




```{r}
rp <- rpart::rpart(formula = WR_Grp~.,data=train1)
rpart::plotcp(rp)
```


```{r}
rpart.plot(rp)
```


__ Falta comentar informações do número de folhas e detalhes do Random Forest__

__ Falta, também, chegar à matriz de confusão e verificar accurácia, sensibilidade, ... com a base de treino e teste__

